{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bfe85d5",
   "metadata": {},
   "source": [
    "Trying various models for sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5cb28f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-2.3.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.10.23-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading numpy-2.3.4-cp312-cp312-macosx_11_0_arm64.whl (14.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyyaml-6.0.3-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading regex-2025.10.23-cp312-cp312-macosx_11_0_arm64.whl (288 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl (208 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, numpy, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [transformers][0m [transformers]ub]er]\n",
      "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.10.5 charset_normalizer-3.4.4 filelock-3.20.0 fsspec-2025.9.0 hf-xet-1.2.0 huggingface-hub-0.36.0 idna-3.11 numpy-2.3.4 pyyaml-6.0.3 regex-2025.10.23 requests-2.32.5 safetensors-0.6.2 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.57.1 typing-extensions-4.15.0 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f61238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf\n",
      "  Downloading protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: tiktoken in ./.venv/lib/python3.12/site-packages (0.12.0)\n",
      "Requirement already satisfied: sentencepiece in ./.venv/lib/python3.12/site-packages (0.2.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.12/site-packages (from tiktoken) (2025.10.23)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.12/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n",
      "Downloading protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Installing collected packages: protobuf\n",
      "Successfully installed protobuf-6.33.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade protobuf tiktoken sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce5a916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nandinibohra/Desktop/VSCodeFiles/CatGPT/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cpu\n",
      "/Users/nandinibohra/Desktop/VSCodeFiles/CatGPT/.venv/lib/python3.12/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n",
      "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at mrm8488/t5-base-finetuned-emotion and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "emotion_model_1 = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "emotion_model_2 = pipeline(\"text-classification\", model=\"mrm8488/t5-base-finetuned-emotion\", return_all_scores=True)\n",
    "emotion_model_3 = pipeline(\"text-classification\", model=\"bhadresh-savani/distilbert-base-uncased-emotion\", return_all_scores=True)\n",
    "emotion_model_4 = pipeline(\"text-classification\", model=\"nateraw/bert-base-uncased-emotion\", return_all_scores=True)\n",
    "\n",
    "# emotion_model_5 = pipeline(\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", return_all_scores=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4bb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: j-hartmann/emotion-english-distilroberta-base\n",
      "  anger: 0.0196\n",
      "  disgust: 0.0205\n",
      "  fear: 0.0046\n",
      "  joy: 0.0019\n",
      "  neutral: 0.0032\n",
      "  sadness: 0.9487\n",
      "  surprise: 0.0015\n",
      "\n",
      "Model: mrm8488/t5-base-finetuned-emotion\n",
      "  LABEL_0: 0.6208\n",
      "  LABEL_1: 0.3792\n",
      "\n",
      "Model: bhadresh-savani/distilbert-base-uncased-emotion\n",
      "  sadness: 0.1444\n",
      "  joy: 0.0256\n",
      "  love: 0.0013\n",
      "  anger: 0.3166\n",
      "  fear: 0.5086\n",
      "  surprise: 0.0034\n",
      "\n",
      "Model: nateraw/bert-base-uncased-emotion\n",
      "  sadness: 0.6891\n",
      "  joy: 0.0081\n",
      "  love: 0.0021\n",
      "  anger: 0.1591\n",
      "  fear: 0.1373\n",
      "  surprise: 0.0042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_emotion_predictions(text):\n",
    "    results = {\n",
    "        \"j-hartmann/emotion-english-distilroberta-base\": emotion_model_1(text),\n",
    "        \"mrm8488/t5-base-finetuned-emotion\": emotion_model_2(text),\n",
    "        \"bhadresh-savani/distilbert-base-uncased-emotion\": emotion_model_3(text),\n",
    "        \"nateraw/bert-base-uncased-emotion\": emotion_model_4(text),\n",
    "        # \"SamLowe/roberta-base-go_emotions\": emotion_model_5(text)\n",
    "    }\n",
    "    return results\n",
    "\n",
    "text = \"I failed my exam today.\"\n",
    "predictions = get_emotion_predictions(text)\n",
    "for model_name, result in predictions.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    for score in result[0]:\n",
    "        print(f\"  {score['label']}: {score['score']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da302597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
